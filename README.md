# ğŸ§¾ Collectibles Spark API

## ğŸ—ï¸ Project Overview

**Collectibles Spark API** is a web service developed in **Java** using the **Spark Framework**, designed to manage collectible items and users in an online store scenario.  
This project represents the first stage (Sprint 1) of a three-phase challenge focused on building a complete web application that streamlines Java web development by reducing configuration files through the use of Sparkâ€™s minimalist microframework.

The goal of Sprint 1 is to implement a functional **RESTful API** capable of handling user operations with complete CRUD functionality (Create, Read, Update, Delete) using HTTP routes and JSON responses.

---

## ğŸ§  Competence and Learning Integration

This project demonstrates the **implementation of Spark Framework** within a Maven-based environment, applying Java web development principles to create modular, maintainable, and scalable applications.

It integrates the following areas of knowledge:

- **Java OOP principles** (encapsulation, classes, and methods)
- **HTTP routing and REST design**
- **API development using Spark Java**
- **Dependency management with Maven**
- **Logging using Logback**
- **Data serialization with Gson**

Through this challenge, I learned to create an API from scratch, manage dependencies, configure routes, and handle requests independently â€” reflecting **C2-level mastery** as defined in the evaluation rubric.

---

## âš™ï¸ Technical Configuration

### ğŸ§© Maven Setup

The project was configured as a Maven application with the following dependencies:

```xml
<dependencies>
  <dependency>
    <groupId>com.sparkjava</groupId>
    <artifactId>spark-core</artifactId>
    <version>2.9.4</version>
  </dependency>

  <dependency>
    <groupId>com.google.code.gson</groupId>
    <artifactId>gson</artifactId>
    <version>2.10.1</version>
  </dependency>

  <dependency>
    <groupId>ch.qos.logback</groupId>
    <artifactId>logback-classic</artifactId>
    <version>1.2.13</version>
  </dependency>
</dependencies>
```

âœ… **Why Spark?**  
Because it eliminates XML configuration files and boilerplate code, allowing fast API setup using concise Java functions.

âœ… **Why Gson?**  
To serialize and deserialize JSON responses, enabling consistent REST communication.

âœ… **Why Logback?**  
To log HTTP activity and exceptions, enhancing debugging and traceability.

---

## ğŸš€ Running the Project

### â–¶ï¸ From IntelliJ IDEA
1. Open `App.java`.
2. Run â†’ **Run 'App.main()'**
3. Access `http://localhost:4567/users`

### â–¶ï¸ From Terminal
```bash
mvn clean package
java -jar target/collectibles-spark-0.1.0.jar
```

Server starts at:
```
== Spark has ignited ...
>> Listening on 0.0.0.0:4567
```

---

## ğŸ”€ Route Definition

According to Sparkâ€™s documentation, each route consists of **three parts: a verb, a route, and a callback**.

| HTTP Verb | Route | Description |
|------------|--------|--------------|
| `GET` | `/users` | Retrieves all users |
| `GET` | `/users/:id` | Retrieves a user by ID |
| `POST` | `/users/:id` | Creates a new user |
| `PUT` | `/users/:id` | Updates user information |
| `OPTIONS` | `/users/:id` | Checks if a user exists |
| `DELETE` | `/users/:id` | Deletes a specific user |
| `GET` | `/health` | Health check route (returns `OK`) |

Each route returns a **JSON-formatted response**, structured through **Gson serialization**, ensuring lightweight data handling.

---

## ğŸ’¡ Example Requests

### ğŸ§  Create User
```bash
curl -X POST http://localhost:4567/users/123   -H "Content-Type: application/json"   -d '{"name":"Rafael","email":"rafa@example.com"}'
```

### ğŸ“‹ Get All Users
```bash
curl http://localhost:4567/users
```

### ğŸ§¾ Update User
```bash
curl -X PUT http://localhost:4567/users/123   -H "Content-Type: application/json"   -d '{"name":"Rafael A.","email":"rafa.a@example.com"}'
```

### âŒ Delete User
```bash
curl -X DELETE http://localhost:4567/users/123
```

**Browser evidence:**  
Accessing `http://localhost:4567/users` shows the JSON list `[ ]` initially, and then displays the created user object after a POST operation.

---

## ğŸ§± Project Structure

```
collectibles-spark/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/com/nao/collectibles/
â”‚   â”‚   â”‚   â”œâ”€â”€ model/User.java
â”‚   â”‚   â”‚   â”œâ”€â”€ store/UserStore.java
â”‚   â”‚   â”‚   â””â”€â”€ App.java
â”‚   â”‚   â””â”€â”€ resources/logback.xml
â”‚   â””â”€â”€ test/
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```

- `App.java`: Contains main method and route definitions.  
- `UserStore.java`: Handles in-memory user CRUD operations.  
- `User.java`: Model class defining user structure.  
- `logback.xml`: Manages log output.  
- `pom.xml`: Dependency management and build configuration.

---

## ğŸ§© Exception and Error Handling

Implemented using Sparkâ€™s built-in mechanisms:

```java
notFound((req, res) -> {
  res.type("application/json");
  return gson.toJson(Map.of("message", "Route not found"));
});

internalServerError((req, res) -> {
  res.type("application/json");
  return gson.toJson(Map.of("message", "Internal server error"));
});
```

âœ… Ensures descriptive error responses instead of generic 404/500 pages.

---

## ğŸŒ Innovation and Impact

### âš™ï¸ Technical Innovation
This project integrates Sparkâ€™s lightweight framework to minimize configuration overhead, drastically improving setup time and readability compared to traditional Java EE approaches.

### ğŸŒ Educational Impact
The project demonstrates how microframeworks can simplify backend development for beginners while maintaining professional-level API standards.

### ğŸ§© Future Expansion
- Persistent database integration (SQLite/MySQL)
- Real-time price updates via WebSockets
- Frontend templates using Mustache

---

## ğŸ“Š Impact Analysis

| Sphere | Description |
|---------|--------------|
| **Technical** | Simplifies the Java web app workflow using Spark, reducing boilerplate code. |
| **Educational** | Enhances understanding of REST API fundamentals, JSON serialization, and backend routing. |
| **Professional** | Prepares for full-stack integration and deployment pipelines in real-world projects. |
| **Social** | Contributes to the development of accessible e-commerce prototypes for small collectors and entrepreneurs. |

---

## ğŸ§  Lessons Learned

- How to configure Maven for dependency management.  
- Defining routes and callbacks in Spark.  
- Testing REST endpoints with `curl`, Postman, and browser.  
- Understanding in-memory storage vs. persistent databases.  
- Importance of structured documentation for project evaluation.

---

## ğŸ“½ï¸ Final Deliverable Summary

- âœ… Functional REST API for user management.  
- âœ… Maven configuration and dependency setup.  
- âœ… Exception handling for 404 and 500 errors.  
- âœ… Evidence screenshots (browser, Postman, console).  
- âœ… Ready for integration with templates and WebSockets in Sprint 2.  

---

## ğŸ§‘â€ğŸ’» Author
**Leonel Campos**  
Biomedical Engineer & Software Developer  
[GitHub Repository Link](https://github.com/your-username/collectibles-spark)
